{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'frontend'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50050\n",
    "\n",
    "# 1) Run with API layer - Director mTLS \n",
    "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
    "# cert_chain = 'cert/root_ca.crt'\n",
    "# API_certificate = 'cert/frontend.crt'\n",
    "# API_private_key = 'cert/frontend.key'\n",
    "\n",
    "# federation = Federation(\n",
    "#     client_id=client_id,\n",
    "#     director_node_fqdn=director_node_fqdn,\n",
    "#     director_port=director_port,\n",
    "#     tls=True,\n",
    "#     cert_chain=cert_chain,\n",
    "#     api_cert=api_certificate,\n",
    "#     api_private_key=api_private_key\n",
    "# )\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2) Run with TLS disabled (trusted environment)\n",
    "# Federation can also determine local fqdn automatically\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sample shape: (300, 400, 3), target shape: (300, 400)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federation.target_shape\n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a FL experiment using Interactive API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register dataset\n",
    "We extract User dataset class implementation. Is it convinient? What if the dataset is not a class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms as tsf\n",
    "\n",
    "\n",
    "class KvasirShardDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self._dataset = dataset\n",
    "        \n",
    "        # Prepare transforms\n",
    "        self.img_trans = tsf.Compose([\n",
    "            tsf.ToPILImage(),\n",
    "            tsf.Resize((332, 332)),\n",
    "            tsf.ToTensor(),\n",
    "            tsf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "        self.mask_trans = tsf.Compose([\n",
    "            tsf.ToPILImage(),\n",
    "            tsf.Resize((332, 332), interpolation=PIL.Image.NEAREST),\n",
    "            tsf.ToTensor()])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img, mask = self._dataset[index]\n",
    "        img = self.img_trans(img).numpy()\n",
    "        mask = self.mask_trans(mask).numpy()\n",
    "        return img, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._dataset)\n",
    "\n",
    "    \n",
    "# Now you can implement you data loaders using dummy_shard_desc\n",
    "class KvasirSD(DataInterface):\n",
    "\n",
    "    def __init__(self, validation_fraction=1/8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.validation_fraction = validation_fraction\n",
    "        \n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "        \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        self._shard_dataset = KvasirShardDataset(shard_descriptor.get_dataset('train'))\n",
    "        \n",
    "        validation_size = max(1, int(len(self._shard_dataset) * self.validation_fraction))\n",
    "        \n",
    "        self.train_indeces = np.arange(len(self._shard_dataset) - validation_size)\n",
    "        self.val_indeces = np.arange(len(self._shard_dataset) - validation_size, len(self._shard_dataset))\n",
    "    \n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        train_sampler = SubsetRandomSampler(self.train_indeces)\n",
    "        return DataLoader(\n",
    "            self._shard_dataset,\n",
    "            num_workers=8,\n",
    "            batch_size=self.kwargs['train_bs'],\n",
    "            sampler=train_sampler\n",
    "        )\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        val_sampler = SubsetRandomSampler(self.val_indeces)\n",
    "        return DataLoader(\n",
    "            self._shard_dataset,\n",
    "            num_workers=8,\n",
    "            batch_size=self.kwargs['valid_bs'],\n",
    "            sampler=val_sampler\n",
    "        )\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.train_indeces)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.val_indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/cloud/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 332, 332])\n",
      "torch.Size([4, 3, 332, 332])\n",
      "torch.Size([1, 3, 332, 332])\n"
     ]
    }
   ],
   "source": [
    "fed_dataset = KvasirSD(train_bs=4, valid_bs=8)\n",
    "fed_dataset.shard_descriptor = dummy_shard_desc\n",
    "for i, (sample, target) in enumerate(fed_dataset.get_train_loader()):\n",
    "    print(sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe a model and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\"\"\"\n",
    "UNet model definition\n",
    "\"\"\"\n",
    "from layers import soft_dice_coef, soft_dice_loss, DoubleConv, Down, Up\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=1):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.up1 = Up(512, 256)\n",
    "        self.up2 = Up(256, 128)\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.outc = nn.Conv2d(64, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x = self.up1(x4, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up3(x, x1)\n",
    "        x = self.outc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "model_unet = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_adam = optim.Adam(model_unet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model_unet, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model_unet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "import torch\n",
    "\n",
    "import tqdm\n",
    "from openfl.component.aggregation_functions import Median\n",
    "\n",
    "# The Interactive API supports registering functions definied in main module or imported.\n",
    "def function_defined_in_notebook(some_parameter):\n",
    "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
    "\n",
    "#The Interactive API supports overriding of the aggregation function\n",
    "aggregation_function = Median()\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@TI.add_kwargs(**{'some_parameter': 42})\n",
    "@TI.register_fl_task(model='unet_model', data_loader='train_loader', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "@TI.set_aggregation_function(aggregation_function)\n",
    "def train(unet_model, train_loader, optimizer, device, loss_fn=soft_dice_loss, some_parameter=None):\n",
    "    \n",
    "    \"\"\"    \n",
    "    The following constructions, that may lead to resource race\n",
    "    is no longer needed:\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        device = 'cpu'\n",
    "    else:\n",
    "        device = 'cuda'\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    print(f'\\n\\n TASK TRAIN GOT DEVICE {device}\\n\\n')\n",
    "    \n",
    "    function_defined_in_notebook(some_parameter)\n",
    "    \n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    \n",
    "    unet_model.train()\n",
    "    unet_model.to(device)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
    "            target).to(device, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        output = unet_model(data)\n",
    "        loss = loss_fn(output=output, target=target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    return {'train_loss': np.mean(losses),}\n",
    "\n",
    "\n",
    "@TI.register_fl_task(model='unet_model', data_loader='val_loader', device='device')     \n",
    "def validate(unet_model, val_loader, device):\n",
    "    print(f'\\n\\n TASK VALIDATE GOT DEVICE {device}\\n\\n')\n",
    "    \n",
    "    unet_model.eval()\n",
    "    unet_model.to(device)\n",
    "    \n",
    "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
    "\n",
    "    val_score = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            samples = target.shape[0]\n",
    "            total_samples += samples\n",
    "            data, target = torch.tensor(data).to(device), \\\n",
    "                torch.tensor(target).to(device, dtype=torch.int64)\n",
    "            output = unet_model(data)\n",
    "            val = soft_dice_coef(output, target)\n",
    "            val_score += val.sum().cpu().numpy()\n",
    "            \n",
    "    return {'dice_coef': val_score / total_samples,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'kvasir_test_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:37:53] </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f85131ff970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f85c1f21070>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:37:55] </span><span style=\"color: #000080\">INFO</span>     Starting experiment!                                                                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:214</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f85131ef250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">ebf78c5fab6f5ee553fb358bdf72f5ce7e638bebd042456a7cdbf9957e5969250739631455c281d53a7c735d125b143b</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f85131e6400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">ebf78c5fab6f5ee553fb358bdf72f5ce7e638bebd042456a7cdbf9957e5969250739631455c281d53a7c735d125b143b</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f85131e2c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">CoreTaskRunner</span> from <span style=\"color: #800000\">openfl.federated.task.task_runner</span> Module.                                                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f85131e2f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f85131e2d60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f851320a190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f851320afa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     SetNewExperiment                                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\"><span style=\"color: #7f7f7f\">director_client.py</span></a><span style=\"color: #7f7f7f\">:203</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f851320ad30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:37:56] </span><span style=\"color: #000080\">INFO</span>     Experiment was accepted and launched.                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:228</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f851320adf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If I use autoreload I got a pickling error\n",
    "\n",
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=fed_dataset,\n",
    "                    rounds_to_train=2,\n",
    "                    opt_treatment='CONTINUE_GLOBAL',\n",
    "                    device_assignment_policy='CUDA_PREFERRED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If user want to stop IPython session, then reconnect and check how experiment is going \n",
    "# fl_experiment.restore_experiment_state(MI)\n",
    "fl_experiment.stream_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:41:52] </span><span style=\"color: #800000; font-weight: bold\">ERROR</span>    The experiment has not been accepted by director                                                                            <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:69</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f851326a1c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000; font-weight: bold\">ERROR</span>    Report the experiment first: use the Experiment.start<span style=\"font-weight: bold\">()</span> method.                                                             <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:70</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f8519d11610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a539666cced0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfl_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\u001b[0m in \u001b[0;36mget_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;34m\"\"\"Retrieve the model with the best score.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_experiment_accepted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         tensor_dict = self.federation.dir_client.get_best_model(\n\u001b[1;32m     79\u001b[0m             experiment_name=self.experiment_name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\u001b[0m in \u001b[0;36m_assert_experiment_accepted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;34m'Report the experiment first: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 'use the Experiment.start() method.')\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = fl_experiment.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:41:34] </span><span style=\"color: #000080\">INFO</span>     Removing experiment data succeed.                                                                                          <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:146</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f85132735b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fl_experiment.remove_experiment_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0956,  0.1751,  0.1613],\n",
       "          [-0.1141, -0.1425,  0.1151],\n",
       "          [-0.0852,  0.0994, -0.0122]],\n",
       "\n",
       "         [[-0.0493, -0.0716,  0.0111],\n",
       "          [ 0.0295, -0.0893,  0.0837],\n",
       "          [ 0.0539,  0.1636,  0.1690]],\n",
       "\n",
       "         [[-0.0064,  0.1558, -0.0073],\n",
       "          [-0.0250,  0.1123, -0.1024],\n",
       "          [-0.1098, -0.1727,  0.1900]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1207, -0.1290, -0.0926],\n",
       "          [-0.1919, -0.1526,  0.0036],\n",
       "          [ 0.1163,  0.0367, -0.1550]],\n",
       "\n",
       "         [[ 0.1090, -0.0954, -0.0448],\n",
       "          [-0.1043,  0.1512,  0.0527],\n",
       "          [ 0.1515,  0.0506,  0.1350]],\n",
       "\n",
       "         [[ 0.1874,  0.1198,  0.1705],\n",
       "          [-0.1859,  0.0457, -0.1156],\n",
       "          [ 0.1084,  0.0545, -0.1601]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0059, -0.0414,  0.0798],\n",
       "          [ 0.1702,  0.0540,  0.0533],\n",
       "          [ 0.0893,  0.0732, -0.1119]],\n",
       "\n",
       "         [[ 0.1652,  0.1654,  0.0648],\n",
       "          [-0.1681, -0.0351, -0.1564],\n",
       "          [-0.0275, -0.0128,  0.0869]],\n",
       "\n",
       "         [[ 0.0361, -0.0294, -0.1786],\n",
       "          [-0.0260,  0.0781,  0.0321],\n",
       "          [ 0.0065, -0.0185,  0.0270]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.1595, -0.0841, -0.0848],\n",
       "          [ 0.0728, -0.0697,  0.0624],\n",
       "          [ 0.0240,  0.1501, -0.1013]],\n",
       "\n",
       "         [[ 0.1587, -0.1635,  0.0293],\n",
       "          [ 0.1803, -0.1098,  0.1094],\n",
       "          [-0.0325,  0.0545, -0.0560]],\n",
       "\n",
       "         [[ 0.0602, -0.0070, -0.0626],\n",
       "          [-0.1199, -0.0054,  0.1829],\n",
       "          [-0.1711, -0.1347, -0.1068]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1751, -0.0318, -0.0026],\n",
       "          [ 0.0469, -0.0367, -0.1335],\n",
       "          [ 0.1731,  0.1570, -0.1101]],\n",
       "\n",
       "         [[-0.1219, -0.1639, -0.0507],\n",
       "          [ 0.0401,  0.1535, -0.1317],\n",
       "          [-0.1186,  0.1921,  0.0923]],\n",
       "\n",
       "         [[-0.1363, -0.1416,  0.1042],\n",
       "          [ 0.0904,  0.0471,  0.0349],\n",
       "          [-0.0223, -0.1889, -0.1563]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0764,  0.0710, -0.1048],\n",
       "          [-0.0964,  0.0393,  0.1438],\n",
       "          [-0.0534, -0.0149,  0.0661]],\n",
       "\n",
       "         [[-0.0802,  0.0681,  0.1575],\n",
       "          [ 0.1803, -0.0610,  0.0531],\n",
       "          [-0.1713, -0.0394,  0.1645]],\n",
       "\n",
       "         [[ 0.0365, -0.0489, -0.1512],\n",
       "          [ 0.1809, -0.0991,  0.0602],\n",
       "          [-0.1367,  0.0413,  0.0591]]]], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.inc.conv[0].weight\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "647db5450d57ba7fc4087705c716e42497ce197267b2ecf05c909328f040bacd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
