{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liquid-jacket",
   "metadata": {},
   "source": [
    "# Federated Learning with Director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "alike-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.federation import Federation\n",
    "from openfl.interface.interactive_api.experiment import TaskInterface, ModelInterface, FLExperiment\n",
    "import sys\n",
    "sys.path.append(\"../utils/\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from loss import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "NUM_CLASSES=1\n",
    "ROUND_TO_TRAIN=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16986f22",
   "metadata": {},
   "source": [
    "# Connect to the Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4485ac79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sample shape: (400, 400, 3), target shape: (400, 400)'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'frontend'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50053\n",
    "\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")\n",
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry\n",
    "federation.target_shape\n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-tyler",
   "metadata": {},
   "source": [
    "## Creating a FL experiment using Interactive API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-public",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-texas",
   "metadata": {},
   "source": [
    "We extract User dataset class implementation.\n",
    "Is it convinient?\n",
    "What if the dataset is not a class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d8df35f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/cloud/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape : torch.Size([4, 3, 332, 332])\n",
      "Target shape : torch.Size([4, 1, 332, 332])\n",
      "Sample shape : torch.Size([4, 3, 332, 332])\n",
      "Target shape : torch.Size([4, 1, 332, 332])\n",
      "Sample shape : torch.Size([1, 3, 332, 332])\n",
      "Target shape : torch.Size([1, 1, 332, 332])\n"
     ]
    }
   ],
   "source": [
    "from gear_shard_dataset import GearSD\n",
    "from kvasir_shard_dataset import KvasirSD\n",
    "\n",
    "fed_dataset = KvasirSD(train_bs=4, valid_bs=8)\n",
    "fed_dataset.shard_descriptor = dummy_shard_desc\n",
    "for i, (sample, target) in enumerate(fed_dataset.get_train_loader()):\n",
    "    print(\"Sample shape : \"+str(sample.shape))\n",
    "    print(\"Target shape : \"+str(target.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-distinction",
   "metadata": {},
   "source": [
    "### Describe a model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "foreign-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DeepLab model definition \n",
    "\"\"\"\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, deeplabv3_mobilenet_v3_large, deeplabv3_resnet101\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=1):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.up1 = Up(512, 256)\n",
    "        self.up2 = Up(256, 128)\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.outc = nn.Conv2d(64, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x = self.up1(x4, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up3(x, x1)\n",
    "        x = self.outc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class DeepLabv3:\n",
    "    def build_deeplab(self, num_features_fc: int=256, backbone: str=\"mobilenetv3\", pretrained_backbone: bool=True, pretrained_head: bool=True, alpha: float=0):\n",
    "        \"\"\" change the output layer and add a freezing coeff.\n",
    "            the number of in channel for the DeepLabHead depends on the backbone, \n",
    "            MobileNetv3 has 960 out channel whereas resnet101 2048\n",
    "        Args: \n",
    "            backbone: str='mobilenetv3' \"pre-trained backbone to download\"\n",
    "        \"\"\"\n",
    "        if backbone == \"mobilenetv3\":\n",
    "            if pretrained_head:\n",
    "                self.model = deeplabv3_mobilenet_v3_large(pretrained=True, pretrained_backbone=True)\n",
    "                out_channel = 960\n",
    "                self.model.classifier = DeepLabHead(out_channel, NUM_CLASSES)\n",
    "                self.model.aux_classifier = nn.Identity()\n",
    "                print(\"[*] Changing head for {} classes and removing aux classifier\".format(NUM_CLASSES))\n",
    "            else:\n",
    "                self.model = deeplabv3_mobilenet_v3_large(pretrained_backbone=True, num_classes=NUM_CLASSES)\n",
    "        elif backbone == \"resnet101\":\n",
    "            if pretrained_head:\n",
    "                self.model= deeplabv3_resnet101(pretrained=True, pretrained_backbone=True)\n",
    "                out_channel = 2048\n",
    "                self.model.classifier = DeepLabHead(out_channel, NUM_CLASSES)\n",
    "                self.model.aux_classifier = nn.Identity()\n",
    "                print(\"[*] Changing head for {} classes and removing aux classifier\".format(NUM_CLASSES))\n",
    "            else:\n",
    "                self.model= deeplabv3_resnet101(pretrained_backbone=True, num_classes=NUM_CLASSES)\n",
    "        else:\n",
    "            assert \"No such backbone\"\n",
    "\n",
    "        if alpha == 0:\n",
    "            self.freeze = False\n",
    "        else:\n",
    "            self.freeze = True\n",
    "            self.alpha=alpha\n",
    "            print(\"[!] This model will be trained using alpha freezing coef = {} meaning {}/{} layers will be freeze\".format(self.alpha, int(self.alpha*sum(1 for x in self.model.parameters())), sum(1 for x in self.model.parameters())))\n",
    "        return self.model\n",
    " \n",
    "    def freeze(self):\n",
    "        if self.freeze:\n",
    "            s = sum(1 for x in self.model.parameters())\n",
    "            l_freeze = int(s*self.alpha)\n",
    "            print(\"{} layers in this model, freezing {} layer\\n\".format(s, l_freeze))\n",
    "            for i,param in enumerate(self.model.parameters()):\n",
    "                param.requires_grad = False\n",
    "                if l_freeze < i:\n",
    "                    break\n",
    "            for name, layer in self.model.named_modules():\n",
    "                print(name, layer)\n",
    "    \n",
    "    def unfreeze(self):\n",
    "        for i,param in enumerate(self.model.parameters()):\n",
    "            param.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2d3c332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Changing head for 1 classes and removing aux classifier\n",
      "[!] This model will be trained using alpha freezing coef = 0.7 meaning 135/193 layers will be freeze\n"
     ]
    }
   ],
   "source": [
    "d = DeepLabv3()\n",
    "model_deeplab = d.build_deeplab(alpha=0.7)\n",
    "model_unet = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6935c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_deeplab\n",
    "# take low learning rate for Tversky loss and to not change so much the current trained weights\n",
    "optimizer_adam = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-passion",
   "metadata": {},
   "source": [
    "#### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "handled-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-groove",
   "metadata": {},
   "source": [
    "### Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "increasing-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from openfl.component.aggregation_functions import Median\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "#CRITERION=torch.nn.MSELoss(reduction='mean')\n",
    "CRITERION=IoULoss\n",
    "CRITERION_VAL=soft_dice_coef\n",
    "\n",
    "# The Interactive API supports registering functions definied in main module or imported.\n",
    "def function_defined_in_notebook(some_parameter):\n",
    "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
    "\n",
    "#The Interactive API supports overriding of the aggregation function\n",
    "aggregation_function = Median()\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@TI.add_kwargs(**{'some_parameter': 42})\n",
    "@TI.register_fl_task(model='model', data_loader='train_loader', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "@TI.set_aggregation_function(aggregation_function)\n",
    "def train(model, train_loader, optimizer, device, loss_fn=CRITERION, some_parameter=None):\n",
    "    # TODO we can tune the loss functon with the aux output and apply a coeff\n",
    "    \"\"\"    \n",
    "    The following constructions, that may lead to resource race\n",
    "    is no longer needed:\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        device = 'cpu'\n",
    "    else:\n",
    "        device = 'cuda'        \n",
    "    \"\"\"\n",
    "\n",
    "    # we freeze the layers during the training (otherwise the opt don't load the model correctly afterwards)\n",
    "    d.freeze()\n",
    "\n",
    "    print(f'\\n\\n TASK TRAIN GOT DEVICE {device}\\n\\n')\n",
    "    \n",
    "    function_defined_in_notebook(some_parameter)\n",
    "    \n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
    "            target).to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)[\"out\"]\n",
    "        \n",
    "        #loss = loss_fn().forward(output, target)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    d.unfreeze()\n",
    "\n",
    "    return {'train_loss (dice loss)': np.mean(losses),}\n",
    "\n",
    "@TI.register_fl_task(model='model', data_loader='val_loader', device='device')     \n",
    "def validate(model, val_loader, device, loss_fn=CRITERION, val_fn=CRITERION_VAL):\n",
    "\n",
    "    print(f'\\n\\n TASK VALIDATE GOT DEVICE {device}\\n\\n')\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
    "    val_score = 0\n",
    "    total_samples = 0\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            samples = target.shape[0]\n",
    "            total_samples += samples\n",
    "            data, target = torch.tensor(data).to(device), \\\n",
    "                torch.tensor(target).to(device, dtype=torch.int64)\n",
    "\n",
    "            output = model(data)[\"out\"]\n",
    "            val = soft_dice_coef(output, target)\n",
    "            val_score += val.sum().cpu().numpy()\n",
    "            losses.append(loss_fn(output, target))\n",
    "\n",
    "    return {'Dice coef': val_score / total_samples, 'val_loss (dice loss)': np.mean(losses)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-bride",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "mature-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'gear_test_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "lightweight-causing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:54:32] </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2e66b35520>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2e57825c40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:54:38] </span><span style=\"color: #000080\">INFO</span>     Starting experiment!                                                                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:214</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2e5746b340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">ebf78c5fab6f5ee553fb358bdf72f5ce7e638bebd042456a7cdbf9957e5969250739631455c281d53a7c735d125b143b</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2e57617490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">ebf78c5fab6f5ee553fb358bdf72f5ce7e638bebd042456a7cdbf9957e5969250739631455c281d53a7c735d125b143b</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2e66839fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CoreTaskRunner</span> from <span style=\"color: #800000\">openfl.federated.task.task_runner</span> Module.                                                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2e66839a60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2e66839c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2e57617130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2e668390d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     SetNewExperiment                                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\"><span style=\"color: #7f7f7f\">director_client.py</span></a><span style=\"color: #7f7f7f\">:203</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2e66839a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:54:42] </span><span style=\"color: #000080\">INFO</span>     Experiment was accepted and launched.                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:228</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f2e668394f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If I use autoreload I got a pickling error\n",
    "\n",
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=fed_dataset,\n",
    "                    rounds_to_train=ROUND_TO_TRAIN,\n",
    "                    opt_treatment='CONTINUE_GLOBAL',\n",
    "                    device_assignment_policy='CUDA_PREFERRED')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f1543a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[10:01:37] </span>METRIC   Round <span style=\"color: #000080; font-weight: bold\">0</span>, collaborator env_one train result train_loss:  <span style=\"color: #000080; font-weight: bold\">0.142438</span>                                                           <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:116</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fc71f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span>METRIC   Round <span style=\"color: #000080; font-weight: bold\">0</span>, collaborator env_one locally_tuned_model_validate result val_loss:     <span style=\"color: #000080; font-weight: bold\">0.022357</span>                                   <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:116</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f96ad2a7df0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span>METRIC   Round <span style=\"color: #000080; font-weight: bold\">0</span>, collaborator env_one locally_tuned_model_validate result iou_score:    <span style=\"color: #000080; font-weight: bold\">0.412877</span>                                   <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:116</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f96acf0b8e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span>METRIC   Round <span style=\"color: #000080; font-weight: bold\">0</span>, collaborator env_one aggregated_model_validate result val_loss:        <span style=\"color: #000080; font-weight: bold\">0.036775</span>                                   <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:116</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f96ad2a7df0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span>METRIC   Round <span style=\"color: #000080; font-weight: bold\">0</span>, collaborator env_one aggregated_model_validate result iou_score:       <span style=\"color: #000080; font-weight: bold\">0.412564</span>                                   <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:116</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fd2efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span>METRIC   Round <span style=\"color: #000080; font-weight: bold\">0</span>, collaborator Aggregator train result train_loss:       <span style=\"color: #000080; font-weight: bold\">0.142438</span>                                                   <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:116</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fc71310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span>METRIC   Round <span style=\"color: #000080; font-weight: bold\">0</span>, collaborator Aggregator locally_tuned_model_validate result val_loss:  <span style=\"color: #000080; font-weight: bold\">0.022357</span>                                   <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:116</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fd2ef70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span>METRIC   Round <span style=\"color: #000080; font-weight: bold\">0</span>, collaborator Aggregator locally_tuned_model_validate result iou_score: <span style=\"color: #000080; font-weight: bold\">0.412877</span>                                   <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:116</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fd2ef40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span>METRIC   Round <span style=\"color: #000080; font-weight: bold\">0</span>, collaborator Aggregator aggregated_model_validate result val_loss:     <span style=\"color: #000080; font-weight: bold\">0.036775</span>                                   <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:116</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fc71a00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span>METRIC   Round <span style=\"color: #000080; font-weight: bold\">0</span>, collaborator Aggregator aggregated_model_validate result iou_score:    <span style=\"color: #000080; font-weight: bold\">0.412564</span>                                   <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:116</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fd2ed60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-fd73d4b2d21b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# fl_experiment.restore_experiment_state(MI)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfl_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\u001b[0m in \u001b[0;36mstream_metrics\u001b[0;34m(self, tensorboard_logs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;34m\"\"\"Stream metrics.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_experiment_accepted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmetric_message_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfederation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             self.logger.metric(\n\u001b[1;32m    117\u001b[0m                 \u001b[0;34mf'Round {metric_message_dict[\"round\"]}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\u001b[0m in \u001b[0;36mstream_metrics\u001b[0;34m(self, experiment_name)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;34m\"\"\"Stream metrics RPC.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirector_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetMetricStreamRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmetric_message\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetMetricStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             yield {\n\u001b[1;32m    266\u001b[0m                 \u001b[0;34m'metric_origin'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetric_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    792\u001b[0m                      and self._state.code is not None))\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m             \u001b[0m_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_response_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/grpc/_common.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwait_complete_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0m_wait_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXIMUM_WAIT_TIMEOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspin_cb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/grpc/_common.py\u001b[0m in \u001b[0;36m_wait_once\u001b[0;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wait_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspin_cb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mwait_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspin_cb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mspin_cb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# If user want to stop IPython session, then reconnect and check how experiment is going \n",
    "# fl_experiment.restore_experiment_state(MI)\n",
    "\n",
    "fl_experiment.stream_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30b301",
   "metadata": {},
   "source": [
    "## Now we validate the best model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "55acff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud/anaconda3/lib/python3.8/site-packages/openfl/plugins/frameworks_adapters/pytorch_adapter.py:47: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  new_state[k] = pt.from_numpy(tensor_dict.pop(k)).to(device)\n"
     ]
    }
   ],
   "source": [
    "best_model = fl_experiment.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9479fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove exremove_experiment_datamove_experiment_datamove_experiment_datariment data from director\n",
    "fl_experiment.remove_experiment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.inc.conv[0].weight\n",
    "# model_unet.inc.conv[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a2acb7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "validate:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " TASK VALIDATE GOT DEVICE cpu\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-160-0f7a9669983a>:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data, target = torch.tensor(data).to(device), \\\n",
      "<ipython-input-160-0f7a9669983a>:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(target).to(device, dtype=torch.int64)\n",
      "/home/cloud/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "validate: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.00042889933683909476, 'iou_score': 0.999981701374054}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating initial model\n",
    "validate(initial_model, fed_dataset.get_valid_loader(), 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c12ca93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validate:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " TASK VALIDATE GOT DEVICE cpu\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-160-0f7a9669983a>:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data, target = torch.tensor(data).to(device), \\\n",
      "<ipython-input-160-0f7a9669983a>:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(target).to(device, dtype=torch.int64)\n",
      "validate: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.00042889933683909476, 'iou_score': 0.999981701374054}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating trained model\n",
    "validate(best_model, fed_dataset.get_valid_loader(), 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6734f6",
   "metadata": {},
   "source": [
    "## We can tune model further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3940e75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[10:03:20] </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f97677bf820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f97677bf820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[10:03:25] </span><span style=\"color: #000080\">INFO</span>     Starting experiment!                                                                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:214</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f96ad21f3a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">7e62f113aa1e7323d0c815d99dc635185e933e1cc28106bbf6e4ba81f1603e589a05f195dac790e1a753d4b59e19489a</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fd0aa30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">7e62f113aa1e7323d0c815d99dc635185e933e1cc28106bbf6e4ba81f1603e589a05f195dac790e1a753d4b59e19489a</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fda53a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CoreTaskRunner</span> from <span style=\"color: #800000\">openfl.federated.task.task_runner</span> Module.                                                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fda57f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fda5970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f96ad2dc040>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fda58b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     SetNewExperiment                                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\"><span style=\"color: #7f7f7f\">director_client.py</span></a><span style=\"color: #7f7f7f\">:203</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fda5970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[10:03:30] </span><span style=\"color: #000080\">INFO</span>     Experiment was accepted and launched.                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:228</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f969fda5b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MI = ModelInterface(model=best_model, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
    "fl_experiment.start(model_provider=MI, task_keeper=TI, data_loader=fed_dataset, rounds_to_train=4, \\\n",
    "                              opt_treatment='CONTINUE_GLOBAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd786d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = fl_experiment.get_best_model()\n",
    "# Validating trained model\n",
    "validate(best_model, fed_dataset.get_valid_loader(), 'cpu')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "647db5450d57ba7fc4087705c716e42497ce197267b2ecf05c909328f040bacd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
