{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "from openfl.interface.interactive_api.experiment import ModelInterface, FLExperiment\n",
    "from openfl.utilities.optimizers.torch import FedProxOptimizer, FedProxAdam\n",
    "\n",
    "\"\"\" Agregation function\"\"\"\n",
    "from openfl.component.aggregation_functions import Median, WeightedAverage, AdagradAdaptiveAggregation\n",
    "from openfl.component.aggregation_functions.core import AdaptiveAggregation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from gear_shard_dataset import GearSD\n",
    "from kvasir_shard_dataset import KvasirSD\n",
    "\n",
    "# Vs Code problem not reloading correctly python module\n",
    "import importlib\n",
    "import loss\n",
    "import models\n",
    "import tasks\n",
    "import aggreg\n",
    "\n",
    "importlib.reload(loss)\n",
    "importlib.reload(models)\n",
    "importlib.reload(tasks)\n",
    "importlib.reload(aggreg)\n",
    "\n",
    "from loss import *\n",
    "from models import *\n",
    "from tasks import Task\n",
    "from aggreg import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "NUM_CLASSES=4\n",
    "ROUND_TO_TRAIN=10\n",
    "\n",
    "DELTA_UPDATE=True\n",
    "\"\"\"Tells if collaborators should send delta updates\n",
    "            for the locally tuned models. If set to False, whole checkpoints will be sent.\"\"\"\n",
    "OPTIMIZER_TREATMENT='CONTINUE_GLOBAL'\n",
    "\"\"\" Valid options: 'RESET' - reinitialize optimizer for every round,\n",
    "            'CONTINUE_LOCAL' - keep local optimizer state,\n",
    "            'CONTINUE_GLOBAL' - aggregate optimizer state.\"\"\"\n",
    "\n",
    "agg_lr=0.1\n",
    "client_id = 'frontend'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50055\n",
    "experiment_name = 'gear_test_experiment'\n",
    "LEARNING_RATE=1e-3\n",
    "TRAIN_BS=16\n",
    "VALID_BS=8\n",
    "\n",
    "# back ground - conveyor - good - notgood\n",
    "weights = [0.5, 0.5, 1, 1]\n",
    "class_weights = torch.FloatTensor(weights)\n",
    "CRITERION=nn.CrossEntropyLoss(weight=class_weights)\n",
    "CRITERION_VAL=mIOU\n",
    "\n",
    "# Once your model is trained, the predict function will outputs a (400,400,num_classes) \n",
    "# mask with probability inside it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## don't forget to launch envoy service\n",
    "### bash start_envoy.sh env_on localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Dataset len 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/cloud/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape : torch.Size([9, 3, 400, 400])\n",
      "Target shape : torch.Size([9, 400, 400])\n"
     ]
    }
   ],
   "source": [
    "# please use the same identificator that was used in signed certificate\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")\n",
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry\n",
    "federation.target_shape\n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "f\"Sample shape: {sample.shape}, target shape: {target.shape}\"\n",
    "\n",
    "#fed_dataset = KvasirSD(train_bs=TRAIN_BS, valid_bs=VALID_BS)\n",
    "fed_dataset = GearSD(num_classes=4, train_bs=TRAIN_BS, valid_bs=VALID_BS)\n",
    "\n",
    "fed_dataset.shard_descriptor = dummy_shard_desc\n",
    "for i, (sample, target) in enumerate(fed_dataset.get_train_loader()):\n",
    "    print(\"Sample shape : \"+str(sample.shape))\n",
    "    print(\"Target shape : \"+str(target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Building model ..\n",
      "[*] Keeping features of deeplabv3, freezing all the model except the head\n",
      "198 layers in this model, freezing 198 layer\n",
      "\n",
      "[*] Changing head for 4 classes and removing aux classifier\n",
      "[*] Done\n",
      "Params to learn:\n",
      "\t classifier.0.convs.0.0.weight\n",
      "\t classifier.0.convs.0.1.weight\n",
      "\t classifier.0.convs.0.1.bias\n",
      "\t classifier.0.convs.1.0.weight\n",
      "\t classifier.0.convs.1.1.weight\n",
      "\t classifier.0.convs.1.1.bias\n",
      "\t classifier.0.convs.2.0.weight\n",
      "\t classifier.0.convs.2.1.weight\n",
      "\t classifier.0.convs.2.1.bias\n",
      "\t classifier.0.convs.3.0.weight\n",
      "\t classifier.0.convs.3.1.weight\n",
      "\t classifier.0.convs.3.1.bias\n",
      "\t classifier.0.convs.4.1.weight\n",
      "\t classifier.0.convs.4.2.weight\n",
      "\t classifier.0.convs.4.2.bias\n",
      "\t classifier.0.project.0.weight\n",
      "\t classifier.0.project.1.weight\n",
      "\t classifier.0.project.1.bias\n",
      "\t classifier.1.weight\n",
      "\t classifier.2.weight\n",
      "\t classifier.2.bias\n",
      "\t classifier.4.weight\n",
      "\t classifier.4.bias\n"
     ]
    }
   ],
   "source": [
    "## Load previous model or build an initial one\n",
    "d = DeepLabv3()\n",
    "model, params_to_update= d.build_deeplab(NUM_CLASSES, alpha=0, keep_features=True)\n",
    "#model = d.build_deeplab(load_from_pkl=True)\n",
    "\n",
    "# take low learning rate for Tversky loss and to not change so much the current trained weights\n",
    "optimizer_adam = optim.Adam(params_to_update, lr=LEARNING_RATE)\n",
    "# we can try SGD\n",
    "optimizer = optim.SGD(params_to_update, lr=LEARNING_RATE, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:26:30] </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907ca5970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907ca5fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:26:35] </span><span style=\"color: #000080\">INFO</span>     Starting experiment!                                                                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:214</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907612340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">309a7dc05a04528eafa867b1232cdcf8214fc7e4a4d1a1e621b707791da103011929dd03c93e63dd504305b3e5cb6954</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc90760dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">309a7dc05a04528eafa867b1232cdcf8214fc7e4a4d1a1e621b707791da103011929dd03c93e63dd504305b3e5cb6954</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907600460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CoreTaskRunner</span> from <span style=\"color: #800000\">openfl.federated.task.task_runner</span> Module.                                                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907600400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907600d00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907670a00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc9076002e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     SetNewExperiment                                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\"><span style=\"color: #7f7f7f\">director_client.py</span></a><span style=\"color: #7f7f7f\">:203</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907600820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:26:39] </span><span style=\"color: #000080\">INFO</span>     Experiment was accepted and launched.                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:228</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907600d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Unexpected <class 'AttributeError'>: 'NoneType' object has no attribute 'last_tensor_dict'\"\n\tdebug_error_string = \"{\"created\":\"@1653056799.900899982\",\"description\":\"Error received from peer ipv4:127.0.0.1:50055\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1062,\"grpc_message\":\"Unexpected <class 'AttributeError'>: 'NoneType' object has no attribute 'last_tensor_dict'\",\"grpc_status\":2}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d1ecbf4deb09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     device_assignment_policy='CUDA_PREFERRED')\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfl_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\u001b[0m in \u001b[0;36mget_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;34m\"\"\"Retrieve the model with the best score.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_experiment_accepted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         tensor_dict = self.federation.dir_client.get_best_model(\n\u001b[0m\u001b[1;32m     79\u001b[0m             experiment_name=self.experiment_name)\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\u001b[0m in \u001b[0;36mget_best_model\u001b[0;34m(self, experiment_name)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;34m\"\"\"Get best model method.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirector_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetTrainedModelRequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBEST_MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_last_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\u001b[0m in \u001b[0;36m_get_trained_model\u001b[0;34m(self, experiment_name, model_type)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         )\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mmodel_proto_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetTrainedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_model_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         tensor_dict, _ = deconstruct_model_proto(\n\u001b[1;32m    246\u001b[0m             \u001b[0mmodel_proto_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    214\u001b[0m                  \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                  compression=None):\n\u001b[0;32m--> 216\u001b[0;31m         response, ignored_call = self._with_call(request,\n\u001b[0m\u001b[1;32m    217\u001b[0m                                                  \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                                                  \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    255\u001b[0m                                                        \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                                                        request)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     def with_call(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;34m\"\"\"See grpc.Future.result.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    239\u001b[0m                  new_details, client_call_details))\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    242\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    932\u001b[0m         state, call, = self._blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    933\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m     def future(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Unexpected <class 'AttributeError'>: 'NoneType' object has no attribute 'last_tensor_dict'\"\n\tdebug_error_string = \"{\"created\":\"@1653056799.900899982\",\"description\":\"Error received from peer ipv4:127.0.0.1:50055\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1062,\"grpc_message\":\"Unexpected <class 'AttributeError'>: 'NoneType' object has no attribute 'last_tensor_dict'\",\"grpc_status\":2}\"\n>"
     ]
    }
   ],
   "source": [
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model)\n",
    "\n",
    "# aggregation function \n",
    "agg_fn=AdagradAdaptiveAggregation(learning_rate=agg_lr, model_interface=MI)\n",
    "\n",
    "TI, validate = Task.createTask(CRITERION, CRITERION_VAL, NUM_CLASSES, aggregation_function=agg_fn)\n",
    "\n",
    "# create an experimnet in federation\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)\n",
    "\n",
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=fed_dataset,\n",
    "                    rounds_to_train=ROUND_TO_TRAIN,\n",
    "                    delta_updates=DELTA_UPDATE,\n",
    "                    opt_treatment=OPTIMIZER_TREATMENT,\n",
    "                    device_assignment_policy='CUDA_PREFERRED')\n",
    "\n",
    "best_model = fl_experiment.get_best_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You may use the same federation object to report another experiment or even schedule several experiments that will be executed in series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream from tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can stream metrics \n",
    "fl_experiment.stream_metrics()\n",
    "!tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your model and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = fl_experiment.get_best_model()\n",
    "torch.save(best_model, \"save/best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = fl_experiment.get_best_model()\n",
    "# we can also retreive last model with get_last_model()\n",
    "\n",
    "#fl_experiment.remove_experiment_data()\n",
    "\n",
    "# Compare initial model \n",
    "validate(CRITERION, CRITERION_VAL, NUM_CLASSES, initial_model, fed_dataset.get_valid_loader(), 'cpu')\n",
    "\n",
    "# With the best model \n",
    "validate(CRITERION, CRITERION_VAL, NUM_CLASSES, best_model, fed_dataset.get_valid_loader(), 'cpu')\n",
    "\n",
    "# We can save the best and use it on runtime \n",
    "# TODO save .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also improve the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud/anaconda3/lib/python3.8/site-packages/openfl/plugins/frameworks_adapters/pytorch_adapter.py:47: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  new_state[k] = pt.from_numpy(tensor_dict.pop(k)).to(device)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:32:58] </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907c06c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907ca58e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:33:04] </span><span style=\"color: #000080\">INFO</span>     Starting experiment!                                                                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:214</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907341190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">64d0add9a7582c6b81cb2e5ecd1dbef0f4d8298eb9cba8908ac8fd822702a4a2c136b379cb7d07742fe0a360126f8c71</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907427040>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">64d0add9a7582c6b81cb2e5ecd1dbef0f4d8298eb9cba8908ac8fd822702a4a2c136b379cb7d07742fe0a360126f8c71</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907432850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CoreTaskRunner</span> from <span style=\"color: #800000\">openfl.federated.task.task_runner</span> Module.                                                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc9074327c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907432fa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907600e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc9074327c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     SetNewExperiment                                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\"><span style=\"color: #7f7f7f\">director_client.py</span></a><span style=\"color: #7f7f7f\">:203</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907432970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:33:09] </span><span style=\"color: #000080\">INFO</span>     Experiment was accepted and launched.                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:228</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fc907432250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = fl_experiment.get_best_model()\n",
    "MI = ModelInterface(model=best_model, optimizer=optimizer, framework_plugin=framework_adapter)\n",
    "fl_experiment.start(model_provider=MI, task_keeper=TI, data_loader=fed_dataset, rounds_to_train=8, \\\n",
    "                              opt_treatment=OPTIMIZER_TREATMENT, delta_updates=True)\n",
    "\n",
    "# optimizer treatment : RESET: the optimizer state is initialized each round from noise\n",
    "#CONTINUE_LOCAL: the optimizer state will be reused locally by every collaborator\n",
    "#CONTINUE_GLOBAL: the optimizerâ€™s state will be aggregated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can create specific task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = task_keeper.get_registered_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_assigner(collaborators, round_number, **kwargs):\n",
    "    collaborator_task_map = {}\n",
    "    exclude_collaborators = ['env_two', 'env_three']\n",
    "    for collaborator_name in collaborators:\n",
    "        if collaborator_name in exclude_collaborators:\n",
    "            continue\n",
    "        collaborator_task_map[collaborator_name] = [\n",
    "            tasks['train'],\n",
    "            tasks['locally_tuned_model_validate'],\n",
    "            tasks['aggregated_model_validate']\n",
    "        ]\n",
    "    return collaborator_task_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_assigner(collaborators, round_number, **kwargs):\n",
    "    \"\"\"Assigning task groups randomly while ensuring target distribution\"\"\"\n",
    "    import random\n",
    "    random.shuffle(collaborators)\n",
    "    collaborator_task_map = {}\n",
    "    for idx, col in enumerate(collaborators):\n",
    "        # select only 70% collaborators for training and validation, 30% for validation\n",
    "        if (idx+1)/len(collaborators) <= 0.7:\n",
    "            collaborator_task_map[col] = tasks.values()  # all three tasks\n",
    "        else:\n",
    "            collaborator_task_map[col] = [tasks['aggregated_model_validate']]\n",
    "    return collaborator_task_map\n",
    "\n",
    "# exclude collaborator\n",
    "\n",
    "shard_registry = federation.get_shard_registry()\n",
    "def filter_by_shard_registry_assigner(collaborators, round_number, **kwargs):\n",
    "    collaborator_task_map = {}\n",
    "    for collaborator in collaborators:\n",
    "        col_status = shard_registry.get(collaborator)\n",
    "        if not col_status or not col_status['is_online']:\n",
    "            continue\n",
    "        node_info = col_status['shard_info'].node_info\n",
    "        # Assign train task if collaborator has GPU with total memory more that 8 GB\n",
    "        if len(node_info.cuda_devices) > 0 and node_info.cuda_devices[0].memory_total > 8 * 1024**3:\n",
    "            collaborator_task_map[collaborator] = [\n",
    "                tasks['train'],\n",
    "                tasks['locally_tuned_model_validate'],\n",
    "                tasks['aggregated_model_validate'],\n",
    "            ]\n",
    "        else:\n",
    "            collaborator_task_map[collaborator] = [\n",
    "                tasks['aggregated_model_validate'],\n",
    "            ]\n",
    "    return collaborator_task_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional vlaidation round\n",
    "\n",
    "rounds_to_train = 3\n",
    "total_rounds = rounds_to_train + 1 # use fl_experiment.start(..., rounds_to_train=total_rounds,...)\n",
    "\n",
    "def assigner_with_last_round_validation(collaborators, round_number, **kwargs):\n",
    "    collaborator_task_map = {}\n",
    "    for collaborator in collaborators:\n",
    "        if round_number == total_rounds - 1:\n",
    "            collaborator_task_map[collaborator] = [\n",
    "                tasks['aggregated_model_validate'],\n",
    "            ]\n",
    "        else:\n",
    "            collaborator_task_map[collaborator] = [\n",
    "                tasks['train'],\n",
    "                tasks['locally_tuned_model_validate'],\n",
    "                tasks['aggregated_model_validate']\n",
    "            ]\n",
    "    return collaborator_task_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"save/best_model.pkl\")\n",
    "\n",
    "im = cv2.imread(\"2022-04-21__15_02_30.bmp\")\n",
    "im_s = cv2.imread(\"2022-04-21__15_02_30_label_ground-truth_semantic.png\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "647db5450d57ba7fc4087705c716e42497ce197267b2ecf05c909328f040bacd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
