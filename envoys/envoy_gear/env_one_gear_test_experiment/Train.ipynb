{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "from openfl.interface.interactive_api.experiment import ModelInterface, FLExperiment\n",
    "from openfl.utilities.optimizers.torch import FedProxOptimizer, FedProxAdam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from gear_shard_dataset import GearSD\n",
    "from kvasir_shard_dataset import KvasirSD\n",
    "\n",
    "# Vs Code problem not reloading correctly python module\n",
    "import importlib\n",
    "import loss\n",
    "import models\n",
    "import tasks\n",
    "importlib.reload(loss)\n",
    "importlib.reload(models)\n",
    "importlib.reload(tasks)\n",
    "\n",
    "from loss import *\n",
    "from models import *\n",
    "from tasks import Task\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "NUM_CLASSES=4\n",
    "ROUND_TO_TRAIN=10\n",
    "\n",
    "client_id = 'frontend'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50055\n",
    "experiment_name = 'gear_test_experiment'\n",
    "LEARNING_RATE=1e-3\n",
    "TRAIN_BS=16\n",
    "VALID_BS=8\n",
    "\n",
    "# back ground - conveyor - good - notgood\n",
    "weights = [0.5, 0.5, 1, 1]\n",
    "class_weights = torch.FloatTensor(weights)\n",
    "CRITERION=nn.CrossEntropyLoss(weight=class_weights)\n",
    "CRITERION_VAL=mIOU\n",
    "\n",
    "# Once your model is trained, the predict function will outputs a (400,400,num_classes) \n",
    "# mask with probability inside it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## don't forget to launch envoy service\n",
    "### bash start_envoy.sh env_on localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Dataset len 10\n",
      "Sample shape : torch.Size([9, 3, 400, 400])\n",
      "Target shape : torch.Size([9, 400, 400])\n"
     ]
    }
   ],
   "source": [
    "# please use the same identificator that was used in signed certificate\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")\n",
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry\n",
    "federation.target_shape\n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "f\"Sample shape: {sample.shape}, target shape: {target.shape}\"\n",
    "\n",
    "#fed_dataset = KvasirSD(train_bs=TRAIN_BS, valid_bs=VALID_BS)\n",
    "fed_dataset = GearSD(num_classes=4, train_bs=TRAIN_BS, valid_bs=VALID_BS)\n",
    "\n",
    "fed_dataset.shard_descriptor = dummy_shard_desc\n",
    "for i, (sample, target) in enumerate(fed_dataset.get_train_loader()):\n",
    "    print(\"Sample shape : \"+str(sample.shape))\n",
    "    print(\"Target shape : \"+str(target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Building model ..\n",
      "[*] Keeping features of deeplabv3, freezing all the model except the head\n",
      "198 layers in this model, freezing 198 layer\n",
      "\n",
      "[*] Changing head for 4 classes and removing aux classifier\n",
      "[*] Done\n",
      "Params to learn:\n",
      "\t classifier.0.convs.0.0.weight\n",
      "\t classifier.0.convs.0.1.weight\n",
      "\t classifier.0.convs.0.1.bias\n",
      "\t classifier.0.convs.1.0.weight\n",
      "\t classifier.0.convs.1.1.weight\n",
      "\t classifier.0.convs.1.1.bias\n",
      "\t classifier.0.convs.2.0.weight\n",
      "\t classifier.0.convs.2.1.weight\n",
      "\t classifier.0.convs.2.1.bias\n",
      "\t classifier.0.convs.3.0.weight\n",
      "\t classifier.0.convs.3.1.weight\n",
      "\t classifier.0.convs.3.1.bias\n",
      "\t classifier.0.convs.4.1.weight\n",
      "\t classifier.0.convs.4.2.weight\n",
      "\t classifier.0.convs.4.2.bias\n",
      "\t classifier.0.project.0.weight\n",
      "\t classifier.0.project.1.weight\n",
      "\t classifier.0.project.1.bias\n",
      "\t classifier.1.weight\n",
      "\t classifier.2.weight\n",
      "\t classifier.2.bias\n",
      "\t classifier.4.weight\n",
      "\t classifier.4.bias\n"
     ]
    }
   ],
   "source": [
    "## Load previous model or build an initial one\n",
    "d = DeepLabv3()\n",
    "model, params_to_update= d.build_deeplab(NUM_CLASSES, alpha=0, keep_features=True)\n",
    "#model = d.build_deeplab(load_from_pkl=True)\n",
    "\n",
    "# take low learning rate for Tversky loss and to not change so much the current trained weights\n",
    "optimizer_adam = optim.Adam(params_to_update, lr=LEARNING_RATE)\n",
    "# we can try SGD\n",
    "optimizer = optim.SGD(params_to_update, lr=LEARNING_RATE, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:09:28] </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f9c53124610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f9c53124130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:09:33] </span><span style=\"color: #000080\">INFO</span>     Starting experiment!                                                                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:214</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f9c542b1a00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">309a7dc05a04528eafa867b1232cdcf8214fc7e4a4d1a1e621b707791da103011929dd03c93e63dd504305b3e5cb6954</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f9d004a5370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">309a7dc05a04528eafa867b1232cdcf8214fc7e4a4d1a1e621b707791da103011929dd03c93e63dd504305b3e5cb6954</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f9d004b7130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CoreTaskRunner</span> from <span style=\"color: #800000\">openfl.federated.task.task_runner</span> Module.                                                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f9d004b7250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f9d004b7a30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f9c53163790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f9c531425b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     SetNewExperiment                                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\"><span style=\"color: #7f7f7f\">director_client.py</span></a><span style=\"color: #7f7f7f\">:203</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f9c53142c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[14:09:38] </span><span style=\"color: #000080\">INFO</span>     Experiment was accepted and launched.                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:228</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f9c53142c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model)\n",
    "\n",
    "TI, validate = Task.createTask(CRITERION, CRITERION_VAL, NUM_CLASSES)\n",
    "\n",
    "# create an experimnet in federation\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)\n",
    "\n",
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=fed_dataset,\n",
    "                    rounds_to_train=ROUND_TO_TRAIN,\n",
    "                    opt_treatment='CONTINUE_GLOBAL',\n",
    "                    device_assignment_policy='CUDA_PREFERRED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You may use the same federation object to report another experiment or even schedule several experiments that will be executed in series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream from tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can stream metrics \n",
    "fl_experiment.stream_metrics()\n",
    "!tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your model and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud/anaconda3/lib/python3.8/site-packages/openfl/plugins/frameworks_adapters/pytorch_adapter.py:47: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  new_state[k] = pt.from_numpy(tensor_dict.pop(k)).to(device)\n"
     ]
    }
   ],
   "source": [
    "best_model = fl_experiment.get_best_model()\n",
    "torch.save(best_model, \"save/best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = fl_experiment.get_best_model()\n",
    "# we can also retreive last model with get_last_model()\n",
    "\n",
    "# We remove exremove_experiment_datamove_experiment_datamove_experiment_datariment data from director\n",
    "fl_experiment.remove_experiment_data()\n",
    "\n",
    "# Compare initial model \n",
    "validate(soft_dice_loss, soft_dice_coef, initial_model, fed_dataset.get_valid_loader(), 'cpu')\n",
    "\n",
    "# With the best model \n",
    "validate(soft_dice_loss, soft_dice_coef, best_model, fed_dataset.get_valid_loader(), 'cpu')\n",
    "\n",
    "# We can save the best and use it on runtime \n",
    "# TODO save .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also improve the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[09:14:04] </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f0808008dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f0808008a00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[09:14:17] </span><span style=\"color: #000080\">INFO</span>     Starting experiment!                                                                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:214</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f07f3d99dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">7e62f113aa1e7323d0c815d99dc635185e933e1cc28106bbf6e4ba81f1603e589a05f195dac790e1a753d4b59e19489a</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f07f3de25e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">7e62f113aa1e7323d0c815d99dc635185e933e1cc28106bbf6e4ba81f1603e589a05f195dac790e1a753d4b59e19489a</span>                 <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f07f3dd25e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CoreTaskRunner</span> from <span style=\"color: #800000\">openfl.federated.task.task_runner</span> Module.                                                  <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f07f3dd2970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f07f3dd2940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f0808075940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f07f3dd2490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     SetNewExperiment                                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\"><span style=\"color: #7f7f7f\">director_client.py</span></a><span style=\"color: #7f7f7f\">:203</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f07f3dd27c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[09:14:23] </span><span style=\"color: #000080\">INFO</span>     Experiment was accepted and launched.                                                                                      <a href=\"file:///home/cloud/anaconda3/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:228</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f07f3dd2e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MI = ModelInterface(model=best_model, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
    "fl_experiment.start(model_provider=MI, task_keeper=TI, data_loader=fed_dataset, rounds_to_train=8, \\\n",
    "                              opt_treatment='CONTINUE_GLOBAL')\n",
    "\n",
    "# optimizer treatment : RESET: the optimizer state is initialized each round from noise\n",
    "#CONTINUE_LOCAL: the optimizer state will be reused locally by every collaborator\n",
    "#CONTINUE_GLOBAL: the optimizerâ€™s state will be aggregated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can create specific task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = task_keeper.get_registered_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_assigner(collaborators, round_number, **kwargs):\n",
    "    collaborator_task_map = {}\n",
    "    exclude_collaborators = ['env_two', 'env_three']\n",
    "    for collaborator_name in collaborators:\n",
    "        if collaborator_name in exclude_collaborators:\n",
    "            continue\n",
    "        collaborator_task_map[collaborator_name] = [\n",
    "            tasks['train'],\n",
    "            tasks['locally_tuned_model_validate'],\n",
    "            tasks['aggregated_model_validate']\n",
    "        ]\n",
    "    return collaborator_task_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_assigner(collaborators, round_number, **kwargs):\n",
    "    \"\"\"Assigning task groups randomly while ensuring target distribution\"\"\"\n",
    "    import random\n",
    "    random.shuffle(collaborators)\n",
    "    collaborator_task_map = {}\n",
    "    for idx, col in enumerate(collaborators):\n",
    "        # select only 70% collaborators for training and validation, 30% for validation\n",
    "        if (idx+1)/len(collaborators) <= 0.7:\n",
    "            collaborator_task_map[col] = tasks.values()  # all three tasks\n",
    "        else:\n",
    "            collaborator_task_map[col] = [tasks['aggregated_model_validate']]\n",
    "    return collaborator_task_map\n",
    "\n",
    "# exclude collaborator\n",
    "\n",
    "shard_registry = federation.get_shard_registry()\n",
    "def filter_by_shard_registry_assigner(collaborators, round_number, **kwargs):\n",
    "    collaborator_task_map = {}\n",
    "    for collaborator in collaborators:\n",
    "        col_status = shard_registry.get(collaborator)\n",
    "        if not col_status or not col_status['is_online']:\n",
    "            continue\n",
    "        node_info = col_status['shard_info'].node_info\n",
    "        # Assign train task if collaborator has GPU with total memory more that 8 GB\n",
    "        if len(node_info.cuda_devices) > 0 and node_info.cuda_devices[0].memory_total > 8 * 1024**3:\n",
    "            collaborator_task_map[collaborator] = [\n",
    "                tasks['train'],\n",
    "                tasks['locally_tuned_model_validate'],\n",
    "                tasks['aggregated_model_validate'],\n",
    "            ]\n",
    "        else:\n",
    "            collaborator_task_map[collaborator] = [\n",
    "                tasks['aggregated_model_validate'],\n",
    "            ]\n",
    "    return collaborator_task_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional vlaidation round\n",
    "\n",
    "rounds_to_train = 3\n",
    "total_rounds = rounds_to_train + 1 # use fl_experiment.start(..., rounds_to_train=total_rounds,...)\n",
    "\n",
    "def assigner_with_last_round_validation(collaborators, round_number, **kwargs):\n",
    "    collaborator_task_map = {}\n",
    "    for collaborator in collaborators:\n",
    "        if round_number == total_rounds - 1:\n",
    "            collaborator_task_map[collaborator] = [\n",
    "                tasks['aggregated_model_validate'],\n",
    "            ]\n",
    "        else:\n",
    "            collaborator_task_map[collaborator] = [\n",
    "                tasks['train'],\n",
    "                tasks['locally_tuned_model_validate'],\n",
    "                tasks['aggregated_model_validate']\n",
    "            ]\n",
    "    return collaborator_task_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"save/best_model.pkl\")\n",
    "\n",
    "im = cv2.imread(\"2022-04-21__15_02_30.bmp\")\n",
    "im_s = cv2.imread(\"2022-04-21__15_02_30_label_ground-truth_semantic.png\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "647db5450d57ba7fc4087705c716e42497ce197267b2ecf05c909328f040bacd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
